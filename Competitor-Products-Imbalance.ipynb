{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Sentiment Data - Imbalance\n",
    "\n",
    "Data (public domain): https://data.world/crowdflower/brands-and-product-emotions\n",
    "\n",
    "Notebook code based on IMDB notebook from bert-sklearn/other_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joseph.porter/Data/nas2019/NAS2019\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from ftfy import fix_text\n",
    " \n",
    "from bert_sklearn import BertClassifier\n",
    "from bert_sklearn import load_model\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "DATAFILE = \"./data/judge-expanded.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11493\n",
      "11492\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>company</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excited to meet the @samsungmobileus at #sxsw ...</td>\n",
       "      <td>Google</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text company  label\n",
       "0   .@wesley83 I have a 3G iPhone. After 3 hrs twe...   Apple     -1\n",
       "1   @jessedee Know about @fludapp ? Awesome iPad/i...   Apple      1\n",
       "2   @swonderlin Can not wait for #iPad 2 also. The...   Apple      1\n",
       "3   @sxsw I hope this year's festival isn't as cra...   Apple     -1\n",
       "4   @sxtxstate great stuff on Fri #SXSW: Marissa M...  Google      1\n",
       "5   @teachntech00 New iPad Apps For #SpeechTherapy...     NaN      0\n",
       "7   #SXSW is just starting, #CTIA is around the co...  Google      1\n",
       "8   Beautifully smart and simple idea RT @madebyma...   Apple      1\n",
       "9   Counting down the days to #sxsw plus strong Ca...   Apple      1\n",
       "10  Excited to meet the @samsungmobileus at #sxsw ...  Google      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "    \n",
    "data = pd.read_csv(DATAFILE)\n",
    "print(len(data))\n",
    "data = data[data['text'].notnull()]\n",
    "print(len(data))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (9281, 3)\n",
      "Test data size: (2211, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test data\n",
    "\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk]\n",
    "test = data[~msk]\n",
    "print('Training data size: ' + str(train.shape))\n",
    "print('Test data size: ' + str(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_dist(dataset, label='label'):\n",
    "    \n",
    "    dist = Counter(dataset[label])\n",
    "    total = len(dataset)\n",
    "    for k,v in sorted(dist.items(), key=lambda x: x[0]):\n",
    "        pct = 100.0 * (float(v)/float(total))\n",
    "        print(f'{k}: {v} ({pct:5.2f}%)')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dist:\n",
      "-1: 2386 (25.71%)\n",
      "0: 4506 (48.55%)\n",
      "1: 2389 (25.74%)\n",
      "None\n",
      "Test dist:\n",
      "-1: 584 (26.41%)\n",
      "0: 1038 (46.95%)\n",
      "1: 589 (26.64%)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Train dist:')\n",
    "print(print_dist(train))\n",
    "print('Test dist:')\n",
    "print(print_dist(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW\",\n",
       "        'Apple', 1]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each review is much longer than a sentence or two. The Google AI BERT models were trained on sequences of max length 512. Lets look at the performance for max_seq_length equal to  128, 256, and 512.\n",
    "\n",
    "### max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 800 \n",
      "Test data size: 500 \n"
     ]
    }
   ],
   "source": [
    "## Set up data for the classifier\n",
    "\n",
    "train = train.sample(800)\n",
    "test = test.sample(500)\n",
    "\n",
    "print(\"Train data size: %d \"%(len(train)))\n",
    "print(\"Test data size: %d \"%(len(test)))\n",
    "\n",
    "X_train = train['text']\n",
    "y_train = train['label']\n",
    "\n",
    "X_test = test['text']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dist:\n",
      "-1: 211 (26.38%)\n",
      "0: 400 (50.00%)\n",
      "1: 189 (23.62%)\n",
      "None\n",
      "Test dist:\n",
      "-1: 141 (28.20%)\n",
      "0: 227 (45.40%)\n",
      "1: 132 (26.40%)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Train dist:')\n",
    "print(print_dist(train))\n",
    "print('Test dist:')\n",
    "print(print_dist(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sklearn text classifier...\n",
      "BertClassifier(bert_config_json=None, bert_model='bert-base-uncased',\n",
      "               bert_vocab=None, do_lower_case=None, epochs=4, eval_batch_size=8,\n",
      "               fp16=False, from_tf=False, gradient_accumulation_steps=1,\n",
      "               ignore_label=None, label_list=[-1, 0, 1], learning_rate=2e-05,\n",
      "               local_rank=-1, logfile='bert_sklearn.log', loss_scale=0,\n",
      "               max_seq_length=128, num_mlp_hiddens=500, num_mlp_layers=0,\n",
      "               random_state=42, restore_file=None, train_batch_size=32,\n",
      "               use_cuda=True, validation_fraction=0.1, warmup_proportion=0.1)\n"
     ]
    }
   ],
   "source": [
    "## Create the model\n",
    "\n",
    "model = BertClassifier(bert_model='bert-base-uncased', label_list=[-1,0,1])\n",
    "model.max_seq_length = 128\n",
    "model.learning_rate = 2e-05\n",
    "model.epochs = 4\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bert-base-uncased model...\n",
      "Defaulting to linear classifier/regressor\n",
      "Loading Pytorch checkpoint\n",
      "train data size: 720, validation data size: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 23/23 [09:21<00:00, 24.39s/it, loss=0.964]\n",
      "Validating: 100%|██████████| 10/10 [00:15<00:00,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.9637, Val loss: 1.2498, Val accy: 31.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 23/23 [08:53<00:00, 23.18s/it, loss=0.77] \n",
      "Validating: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.7700, Val loss: 0.6694, Val accy: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 23/23 [08:45<00:00, 22.86s/it, loss=0.674]\n",
      "Validating: 100%|██████████| 10/10 [00:16<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6739, Val loss: 0.6430, Val accy: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 23/23 [08:52<00:00, 23.14s/it, loss=0.651]\n",
      "Validating: 100%|██████████| 10/10 [00:16<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 0.6507, Val loss: 0.6354, Val accy: 70.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 63/63 [01:48<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6386, Accuracy: 69.20%\n",
      "CPU times: user 1h 39min 57s, sys: 8min 35s, total: 1h 48min 33s\n",
      "Wall time: 38min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Train the model using our data (this could take a while)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accy = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 720, validation data size: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 23/23 [08:46<00:00, 22.90s/it, loss=0.684]\n",
      "Validating: 100%|██████████| 10/10 [00:15<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.6838, Val loss: 0.5731, Val accy: 78.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 23/23 [08:51<00:00, 23.12s/it, loss=0.654]\n",
      "Validating: 100%|██████████| 10/10 [00:15<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.6539, Val loss: 0.4888, Val accy: 82.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 23/23 [08:44<00:00, 22.80s/it, loss=0.618]\n",
      "Validating: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train loss: 0.6181, Val loss: 0.5399, Val accy: 83.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 23/23 [08:43<00:00, 22.76s/it, loss=0.573]\n",
      "Validating: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train loss: 0.5730, Val loss: 0.4612, Val accy: 78.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 63/63 [01:35<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6648, Accuracy: 68.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, load_at_start=False)\n",
    "accy2 = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 63/63 [01:48<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.85      0.90       141\n",
      "           0       0.60      0.97      0.74       227\n",
      "           1       0.33      0.02      0.04       132\n",
      "\n",
      "    accuracy                           0.69       500\n",
      "   macro avg       0.63      0.61      0.56       500\n",
      "weighted avg       0.63      0.69      0.60       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, labels=[-1,0,1])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 720, validation data size: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training  : 100%|██████████| 23/23 [09:24<00:00, 24.55s/it, loss=0.672]\n",
      "Validating: 100%|██████████| 10/10 [00:17<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss: 0.6720, Val loss: 0.5317, Val accy: 80.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  : 100%|██████████| 23/23 [09:23<00:00, 24.51s/it, loss=0.619]\n",
      "Validating: 100%|██████████| 10/10 [00:16<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train loss: 0.6194, Val loss: 0.5671, Val accy: 80.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 63/63 [01:40<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6646, Accuracy: 67.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.epochs = 2\n",
    "model.fit(X_train, y_train, load_at_start=False)\n",
    "accy3 = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 63/63 [01:47<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.84      0.86       141\n",
      "           0       0.60      0.97      0.74       227\n",
      "           1       0.00      0.00      0.00       132\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.50      0.60      0.53       500\n",
      "weighted avg       0.52      0.68      0.58       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/anaconda3/envs/bert/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred, labels=[-1,0,1])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.epochs = 2\n",
    "model.fit(X_train, y_train, load_at_start=False)\n",
    "accy3 = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 -1  0  0  0  1  0\n",
      " -1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0 -1  0  0  0  0 -1  0  0 -1\n",
      "  0 -1 -1  0 -1  0  0  0 -1  1 -1  0  0 -1 -1  0  0  0  0  0 -1  0  0  0\n",
      " -1  0 -1  0  0  0  1  0  0  0  0 -1  0  0  0 -1  0  0  0  0  0 -1  0  0\n",
      "  0 -1  0  0]\n",
      "7672     0\n",
      "1885     1\n",
      "3589     1\n",
      "7844     1\n",
      "5737    -1\n",
      "        ..\n",
      "5248     0\n",
      "6283     0\n",
      "10614   -1\n",
      "8187     1\n",
      "3719     0\n",
      "Name: label, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[100:200])\n",
    "print(y_test[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 1\n"
     ]
    }
   ],
   "source": [
    "print(np.min(y_pred), np.max(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean      -0.018000\n",
       "std        0.739439\n",
       "min       -1.000000\n",
       "25%       -1.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(y_test))\n",
    "y_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9803688  0.01074482 0.00888633]\n",
      " [0.9852483  0.00825785 0.00649386]\n",
      " [0.9806912  0.0106124  0.00869637]\n",
      " [0.9810533  0.01045346 0.00849328]\n",
      " [0.9809466  0.01066898 0.0083844 ]\n",
      " [0.9802644  0.0111946  0.00854098]]\n",
      "CPU times: user 3.34 s, sys: 284 ms, total: 3.63 s\n",
      "Wall time: 1.33 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Test out the model with our own invented examples!\n",
    "\n",
    "examples = [\n",
    "    'This Android product is not very good',\n",
    "    'I could not get that iPhone to work, so I sent it back. I''m really upset!',\n",
    "    'Another great product from the folks at Google!  We really liked it a lot',\n",
    "    'My iPad is essential - of course I would buy another one!',\n",
    "    'When in the course of human events it becomes necessary to dissolve those ties...',\n",
    "    'We the people, in order to form a more perfect union, establish justice, insure domestic tranquility, ...'\n",
    "]\n",
    "\n",
    "print(model.predict_proba(examples))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model1_128_bb_uncased.mdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_seq_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Don't use this one - it will take a very long time!\n",
    "\n",
    "model = BertClassifier(bert_model='bert-base-uncased', label_list=[-1,0,1])\n",
    "model.max_seq_length = 256\n",
    "model.train_batch_size = 32\n",
    "model.learning_rate = 2e-05\n",
    "model.epochs = 4\n",
    "\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accy = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Don't use this one - it will take the longest of all!\n",
    "\n",
    "model = BertClassifier(bert_model='bert-base-uncased', label_list=[-1,0,1])\n",
    "model.max_seq_length = 512\n",
    "\n",
    "# max_seq_length=512 will use a lot more GPU mem, so I am turning down batch size \n",
    "# and adding gradient accumulation steps\n",
    "model.train_batch_size = 16\n",
    "model_gradient_accumulation_steps = 4\n",
    "\n",
    "model.learning_rate = 2e-05\n",
    "model.epochs = 4\n",
    "\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accy = model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
